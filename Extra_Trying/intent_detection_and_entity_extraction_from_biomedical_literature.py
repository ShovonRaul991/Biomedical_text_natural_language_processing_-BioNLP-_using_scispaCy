# -*- coding: utf-8 -*-
"""Intent_Detection_and_Entity_Extraction_from_BioMedical_Literature.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNrhTFGe1_0EsZLh-EayFNnFpp1s_XcV
"""

import re
import json
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

# Load the model and tokenizer for BINDER-PubMedBERT (NER)
binder_tokenizer = AutoTokenizer.from_pretrained("bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12")
binder_model = AutoModelForTokenClassification.from_pretrained("bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12")

# Load the model and tokenizer for RoBERTa (Intent Detection)
roberta_tokenizer = AutoTokenizer.from_pretrained("roberta-base")
roberta_model = AutoModelForTokenClassification.from_pretrained("roberta-base")

# Load the model and tokenizer for PubMedBERT (NER)
pubmed_tokenizer = AutoTokenizer.from_pretrained("microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext")
pubmed_model = AutoModelForTokenClassification.from_pretrained("microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext")

# Create pipelines for named entity recognition (NER) and intent detection
binder_ner_pipeline = pipeline("ner", model=binder_model, tokenizer=binder_tokenizer)
pubmed_ner_pipeline = pipeline("ner", model=pubmed_model, tokenizer=pubmed_tokenizer)
roberta_intent_pipeline = pipeline("ner", model=roberta_model, tokenizer=roberta_tokenizer)

# Sample text
text = "However, it's important to consult a healthcare professional if symptoms persist or worsen, as they could indicate a more serious underlying condition"
text4 = "On the other hand, individuals might ask about the best practices for maintaining a healthy lifestyle, including diet and exercise routines."
text3 = "Additionally, concerns about mental health issues, such as anxiety or depression, are frequently raised, prompting discussions about therapy options or medication management."
text1 = "Pharmacokinetic properties of abacavir were not altered by the addition of either lamivudine or zidovudine."
text2 = "People may also inquire about preventive measures against contagious diseases, especially during flu season or outbreaks."

# Perform named entity recognition using PubMedBERT
pubmed_ner_results = pubmed_ner_pipeline(text)


# Initialize lists to store medical and generic entities
medical_entities = []
generic_entities = []

# Classify entities as medical or generic
for entity in pubmed_ner_results:
    if entity['score'] > 0.5:  # Adjust score threshold as needed
        medical_entities.append(entity['word'])
    else:
        generic_entities.append(entity['word'])

# Print results
print("Medical Entities detected by PubMedBERT:")
for entity in medical_entities:
    print(entity)

print("\nGeneric Entities detected by PubMedBERT:")
for entity in generic_entities:
    print(entity)

# Perform named entity recognition using BINDER-PubMedBERT
binder_ner_results = binder_ner_pipeline(text)

# Initialize lists to store medical and generic entities
medical_entities = []
generic_entities = []

# Classify entities as medical or generic
for entity in pubmed_ner_results:
    if entity['score'] > 0.5:  # Adjust score threshold as needed
        medical_entities.append(entity['word'])
    else:
        generic_entities.append(entity['word'])

# Print results
print("Medical Entities detected by BINDER-PubMedBERT:")
for entity in medical_entities:
    print(entity)

print("\nGeneric Entities detected by BINDER-PubMedBERT:")
for entity in generic_entities:
    print(entity)

# Perform intent detection using RoBERTa
intent_results = roberta_intent_pipeline(text)

# Classify intent based on the output of RoBERTa pipeline
intent_label = "Medical Inquiry" if any(token['entity'] == 'LABEL_1' and token['score'] > 0.6 for token in intent_results) else "General Inquiry"

# Initialize a list to store JSON-serializable intent data
json_serializable_intent = []


# Iterate over each token in the intent results and extract JSON-serializable information
for token in intent_results:
    token_info = {
        "word": token.get("word", ""),
        "entity": token.get("entity", ""),
        "score": float(token.get("score", 0.0)),  # Convert to float
        "index": int(token.get("index", 0)),      # Convert to integer
        "start": int(token.get("start", 0)),      # Convert to integer
        "end": int(token.get("end", 0))           # Convert to integer
    }
    json_serializable_intent.append(token_info)

# Specify the file path to save the JSON file
file_path = "output.json"

# Write JSON data to file
with open(file_path, "w") as json_file:
    json.dump(json_serializable_intent, json_file, indent=4)

print(f"JSON data has been saved to {file_path}.")


print("\nIntent label:", intent_label)